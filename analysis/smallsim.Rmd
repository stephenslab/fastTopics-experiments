---
title: A small simulation illustrating the trouble with EM
author: Peter Carbonetto
output: workflowr::wflow_html
---

This is a small numerical experiment to give some intuition for why
the EM algorithm for Poisson NMF performs poorly in some settings.
This example suggests that the EM updates have difficulty with
correlations between topics, even when they are quite modest,

```{r knitr-opts, include=FALSE}
knitr::opts_chunk$set(comment = "#",collapse = TRUE,results = "hold",
                      fig.align = "center",dpi = 120)
```

Load the packages used in the analysis below, as well as additional
functions that we will use to simulate the data.

```{r load-pkgs, message=FALSE}
library(fastTopics)
library(mvtnorm)
library(ggplot2)
library(cowplot)
source("../code/smallsim_functions.R")
```

Set the seed so that the results can be reproduced.

```{r set-seed}
set.seed(1)
```

Independent topics scenario
---------------------------

In this first example, we simulate a $100 \times 400$ counts matrix
from a multinomial topic model with $K = 6$ topics.

```{r simulate-data-1}
n <- 100
m <- 400
k <- 6
S <- 13*diag(k) - 2
F <- simulate_factors(m,k)
L <- simulate_loadings(n,k,S)
s <- simulate_sizes(n)
X <- simulate_multinom_counts(L,F,s)
X <- X[,colSums(X > 0) > 0]
```

The topic proportions for each of the 100 samples---that is, a row of
the counts matrix---are randomly drawn according to the
[correlated topic model](https://doi.org/10.1214/07-AOAS114): $\eta_i$
for row $i$ is drawn from the multivariate normal with mean zero and
covariance matrix $S$, such that $s_{kk} = 11$, $s_{jk} = -2$ for all
$j \neq k$. Generated in this way, the topic proportions tend to be
roughly orthogonal:

TO DO: Hide code for plots inside functions.

```{r structure-plot-1, fig.width=6, fig.height=1.5, message=FALSE}
topic_colors <- c("dodgerblue","darkorange","forestgreen","darkblue",
                  "gold","skyblue")
y <- apply(L,1,which.max)
y <- rank(y,ties.method = "random")
y <- qqnorm(y,plot.it = FALSE)$x
fit <- list(L = L)
class(fit) <- c("multinom_topic_model_fit","list")
structure_plot(fit,topics = 1:6,colors = topic_colors,perplexity = 30,
               Y_init = matrix(y),verbose = FALSE)
```

Here we compare two different updates for fitting a Poisson NMF model
to the simulated counts: EM updates, and sequential coordinate descent
(SCD). We perform 150 iterations of each. The model fitting is
initialized by first running 50 EM updates, with the aim of better
ensuring that the same local maximum is recovered by both runs.

```{r fit-1, results="hide", message=FALSE}
fit0 <- fit_poisson_nmf(X,k,numiter = 50,method = "em",
                        control = list(extrapolate = FALSE,numiter = 4))
fit1 <- fit_poisson_nmf(X,fit0 = fit0,numiter = 150,method = "em",
                        control = list(extrapolate = FALSE,numiter = 4))
fit2 <- fit_poisson_nmf(X,fit0 = fit0,numiter = 150,method = "scd",
                        control = list(extrapolate = FALSE,numiter = 4))
fit1 <- poisson2multinom(fit1)
fit2 <- poisson2multinom(fit2)
```

This next plot shows the improvement in the solution over time for the
EM and SCD updates. The Y axis shows the difference between the
current log-likelihood and the best log-likelihood achieved by the two
methods.

```{r plot-progress-1, fig.width=6, fig.height=2}
pdat <- rbind(data.frame(iter   = 1:200,
                         loglik = fit1$progress$loglik.multinom,
                         res    = fit1$progress$res,
                         method = "em"),
              data.frame(iter   = 1:200,
						 loglik = fit2$progress$loglik.multinom,
						 res    = fit2$progress$res,
						 method = "scd"))
pdat <- transform(pdat,loglik = max(loglik) - loglik)
pdat <- subset(pdat,iter >= 50)
p1 <- ggplot(pdat,aes(x = iter,y = loglik,color = method)) +
  geom_line(size = 0.75) +
  scale_color_manual(values = c("dodgerblue","darkorange")) +
  labs(x = "iteration",y = "log-likelihood difference") +
  theme_cowplot(font_size = 10)
p2 <- ggplot(pdat,aes(x = iter,y = res,color = method)) +
  geom_line(size = 0.75) +
  scale_color_manual(values = c("dodgerblue","darkorange")) +
  labs(x = "iteration",y = "max KKT residual") +
  theme_cowplot(font_size = 10)
plot_grid(p1,p2)
```

Among the two methods compared, the SCD updates progress more rapidly
toward a solution. Still, the EM updates recover the same solution
after a reasonable number of iterations. Indeed, the EM and SCD
estimates of the topic proportions are almost the same:

```{r loadings-scatterplot-1, fig.width=3, fig.height=2.5}
pdat <- data.frame(x = as.vector(fit1$L),
                   y = as.vector(fit2$L),
                   k = factor(rep(1:6,each = 100)))
ggplot(pdat,aes(x = x,y = y,fill = k)) +
  geom_point(color = "white",shape = 21,size = 1.75) +
  geom_abline(intercept = 0,slope = 1,color = "skyblue",linetype = "dotted") +
  scale_fill_manual(values = topic_colors) +
  labs(x = "em",y = "scd") +
  theme_cowplot(font_size = 10)
```

Next we will see an example in which EM updates fail to make
reasonable progress.

Correlated topics scenario
--------------------------

The count data in this second example are simulated as before, with
one difference: by setting $s_{56} = s_{65} = 8$, the mixture
proportions for topics 5 and 6 are no longer close to orthogonal.

```{r simulate-data-2}
set.seed(1)
S[5,6] <- 8
S[6,5] <- 8
L <- simulate_loadings(n,k,S)
X <- simulate_multinom_counts(L,F,s)
X <- X[,colSums(X > 0) > 0]
```

Compare this Structure plot to the one above---there is more mixing of
topics 5 and 6:

```{r structure-plot-2, fig.width=6, fig.height=1.5, message=FALSE}
y <- apply(L,1,which.max)
y <- rank(y,ties.method = "random")
y <- qqnorm(y,plot.it = FALSE)$x
fit <- list(L = L)
class(fit) <- c("multinom_topic_model_fit","list")
structure_plot(fit,topics = 1:6,colors = topic_colors,perplexity = 30,
               Y_init = matrix(y),verbose = FALSE)
```

As before, we run the EM and SCD updates to fit the multinomial topic
model, with a twist that we perform another round of SCD updates after
running the EM updates. This will be explained shortly.

```{r fit-5, results="hide", message=FALSE}
fit0 <- fit_poisson_nmf(X,k,numiter = 50,method = "em",
                        control = list(extrapolate = FALSE,numiter = 4))
fit1 <- fit_poisson_nmf(X,fit0 = fit0,numiter = 750,method = "em",
                        control = list(extrapolate = FALSE,numiter = 4))
fit2 <- fit_poisson_nmf(X,fit0 = fit0,numiter = 950,method = "scd",
                        control = list(extrapolate = FALSE,numiter = 4))
fit3 <- fit_poisson_nmf(X,fit0 = fit1,numiter = 200,method = "scd",
                        control = list(extrapolate = FALSE,numiter = 4))
fit1 <- fit_poisson_nmf(X,fit0 = fit1,numiter = 200,method = "em",
                        control = list(extrapolate = FALSE,numiter = 4))
fit1 <- poisson2multinom(fit1)
fit2 <- poisson2multinom(fit2)
fit3 <- poisson2multinom(fit3)
```

In this second example, after initially making good progress, the EM
estimates remain very far from the solution achieved by SCD even after
hundreds of EM updates. This isn't a case where the EM updates have
settled on a different local solution---the SCD updates quickly
"rescue" the EM estimates.

```{r plot-progress-2, fig.width=6, fig.height=2}
pdat <- rbind(data.frame(iter   = 1:1000,
                         loglik = fit1$progress$loglik.multinom,
                         res    = fit1$progress$res,
                         method = "em"),
              data.frame(iter   = 1:1000,
                         loglik = fit2$progress$loglik.multinom,
                         res    = fit2$progress$res,
                         method = "scd"),
              data.frame(iter   = 800:1000,
                         loglik = fit3$progress[800:1000,"loglik.multinom"],
                         res    = fit3$progress[800:1000,"res"],
  			             method = "em+scd"))
pdat <- transform(pdat,loglik = max(loglik) - loglik)
pdat <- subset(pdat,iter >= 50)
p3 <- ggplot(pdat,aes(x = iter,y = loglik,color = method)) +
  geom_line(size = 0.75) +
  scale_color_manual(values = c("dodgerblue","darkorange","magenta")) +
  labs(x = "iteration",y = "log-likelihood difference") +
  theme_cowplot(font_size = 10)
p4 <- ggplot(pdat,aes(x = iter,y = res,color = method)) +
  geom_line(size = 0.75) +
  scale_color_manual(values = c("dodgerblue","darkorange","magenta")) +
  ylim(0,10) +
  labs(x = "iteration",y = "max KKT residual") +
  theme_cowplot(font_size = 10)
plot_grid(p3,p4)
```

This large difference in likelihood is not due to a trivial difference
in solution---for example, there are many large differences in the
topic proportion estimates:

```{r loadings-scatterplot-2, fig.width=3, fig.height=2.5}
pdat <- data.frame(x = as.vector(fit1$L),
                   y = as.vector(fit2$L),
                   k = factor(rep(1:6,each = 100)))
ggplot(pdat,aes(x = x,y = y,fill = k)) +
  geom_point(color = "white",shape = 21,size = 1.75) +
  geom_abline(intercept = 0,slope = 1,color = "skyblue",linetype = "dotted") +
  scale_fill_manual(values = topic_colors) +
  labs(x = "em",y = "scd") +
  theme_cowplot(font_size = 10)
```

Most of the samples contributing to the large difference in likehood
are samples generated from combinations of topics 5 and 6 (the X and Y
axes in this scatterplot show the per-sample log-likelihoods):

```{r likelihood-scatterplot, fig.width=3.5, fig.height=2.5}
pdat <- data.frame(x = loglik_multinom_topic_model(X,fit1),
                   y = loglik_multinom_topic_model(X,fit2))
ggplot(pdat,aes(x = x,y = y,fill = L[,5] + L[,6])) +
  geom_point(color = "white",shape = 21,size = 1.75) +
  geom_abline(intercept = 0,slope = 1,color = "black",linetype = "dotted") +
  scale_fill_gradient(low = "skyblue",high = "orangered") +
  xlim(-700,-100) +
  ylim(-700,-100) +
  labs(x = "em",y = "scd",fill = "topic 5 + 6") +
  theme_cowplot(font_size = 10)
```

These results suggest that the EM algorithm may perform poorly in
settings where the topics are correlated, even if the correlations are
quite modest.
