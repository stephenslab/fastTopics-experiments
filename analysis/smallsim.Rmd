---
title: EM vs. SCD for fitting a Poisson NMF model and a topic model to a small, simulated data set
author: Peter Carbonetto
output: workflowr::wflow_html
---

Here we perform a small experiment with simulated data to illustrate
the behaviour of the EM and SCD algorithms for fitting Poisson NMF
models. This example suggests that the EM updates have difficulty with
correlations between topics, even when they are quite modest, The
results also suggest that the basic variational EM for LDA also
experiences similar difficulties.

```{r knitr-opts, include=FALSE}
knitr::opts_chunk$set(comment = "#",collapse = TRUE,results = "hold",
                      fig.align = "center",dpi = 120)
```

Load the packages used in the analysis below, as well as additional
functions that we will use to simulate the data.

```{r load-pkgs, message=FALSE}
library(tm)
library(topicmodels)
library(fastTopics)
library(mvtnorm)
library(ggplot2)
library(cowplot)
source("../code/smallsim_functions.R")
```

Set the seed so that the results can be reproduced.

```{r set-seed}
set.seed(1)
```

Independent topics scenario
---------------------------

In this first example, we simulate a $100 \times 400$ counts matrix
from a multinomial topic model with $K = 6$ topics.

```{r simulate-data-1}
n <- 100
m <- 400
k <- 6
S <- 13*diag(k) - 2
F <- simulate_factors(m,k)
L <- simulate_loadings(n,k,S)
s <- simulate_sizes(n)
X <- simulate_multinom_counts(L,F,s)
X <- X[,colSums(X > 0) > 0]
```

The topic proportions for each of the 100 samples---that is, a row of
the counts matrix---are randomly drawn according to the
[correlated topic model](https://doi.org/10.1214/07-AOAS114): $\eta_i$
for row $i$ is drawn from the multivariate normal with mean zero and
covariance matrix $S$, such that $s_{kk} = 11$, $s_{jk} = -2$ for all
$j \neq k$. Generated in this way, the topic proportions tend to be
roughly orthogonal:

```{r structure-plot-1, fig.width=6, fig.height=1.5, message=FALSE}
topic_colors <- c("dodgerblue","darkorange","forestgreen","darkblue",
                  "gold","skyblue")
p1 <- simdata_structure_plot(L,topic_colors)
print(p1)
```

Here we compare two different updates for fitting a Poisson NMF model
to the simulated counts: EM updates, and sequential coordinate descent
(SCD). We perform 100 iterations of each. The model fitting is
initialized by first running 50 EM updates, with the aim of better
ensuring that the same local maximum is recovered by both runs.

```{r fit-1, results="hide", message=FALSE}
control <- list(extrapolate = FALSE,numiter = 4)
fit0 <- fit_poisson_nmf(X,k,numiter = 50,method = "em",control = control)
fit1 <- fit_poisson_nmf(X,fit0=fit0,numiter=100,method="em",control=control)
fit2 <- fit_poisson_nmf(X,fit0=fit0,numiter=100,method="scd",control=control)
fit0 <- poisson2multinom(fit0)
fit1 <- poisson2multinom(fit1)
fit2 <- poisson2multinom(fit2)
```

This next plot shows the improvement in the solution over time for the
EM and SCD updates. The Y axis shows the difference between the
current log-likelihood and the best log-likelihood achieved by the two
methods.

```{r plot-progress-1, fig.width=6, fig.height=2}
pdat <- rbind(data.frame(iter   = 1:150,
                         loglik = fit1$progress$loglik.multinom,
                         res    = fit1$progress$res,
                         method = "em"),
              data.frame(iter   = 1:150,
						 loglik = fit2$progress$loglik.multinom,
						 res    = fit2$progress$res,
						 method = "scd"))
pdat <- subset(pdat,iter >= 50)
pdat <- transform(pdat,
                  iter   = iter - 50,
                  loglik = max(loglik) - loglik + 0.1)
p2 <- ggplot(pdat,aes(x = iter,y = loglik,color = method)) +
  geom_line(size = 0.75) +
  scale_y_continuous(trans = "log10") +
  scale_color_manual(values = c("dodgerblue","darkorange")) +
  labs(x = "iteration",y = "loglik difference") +
  theme_cowplot(font_size = 10)
p3 <- ggplot(pdat,aes(x = iter,y = res,color = method)) +
  geom_line(size = 0.75) +
  scale_color_manual(values = c("dodgerblue","darkorange")) +
  labs(x = "iteration",y = "max KKT residual") +
  theme_cowplot(font_size = 10)
plot_grid(p2,p3)
```

Among the two methods compared, the SCD updates progress more rapidly
toward a solution. Still, the EM updates recover the same solution
after a reasonable number of iterations. Indeed, the EM and SCD
estimates of the topic proportions are almost the same:

```{r loadings-scatterplot-1, fig.width=3, fig.height=2.5}
p4 <- loadings_scatterplot(fit1,fit2,topic_colors,"em","scd")
print(p4)
```

Next, we turn to the problem of fitting an LDA model to the same
data. Although the LDA fitting problem is different---we are now
fitting a (approximate) posterior distribution, and so the estimates
are approximate posterior means rather than MELs---initializing the
LDA fit using the MLEs greatly improves the LDA model fitting, as we
will see here.

We perform 400 iterations of variational EM, initializing the LDA
model fits using the MLEs computed above.

```{r fit-lda-1}
lda0 <- run_lda(X,fit0,numiter = 400)
lda1 <- run_lda(X,fit1,numiter = 400)
lda2 <- run_lda(X,fit2,numiter = 400)
```

Even after 400 iterations, variational EM without a good
initialization does not approach the quality of the LDA model fits
initialized using the EM and SCD estimates.

```{r plot-progress-lda-1, fig.width=2.5, fig.height=2}
pdat <- rbind(data.frame(iter = 1:400,elbo = lda0@logLiks,init = "none"),
              data.frame(iter = 1:400,elbo = lda1@logLiks,init = "em"),
              data.frame(iter = 1:400,elbo = lda2@logLiks,init = "scd"))
pdat <- transform(pdat,elbo = max(elbo) - elbo + 0.1)
p5 <- ggplot(pdat,aes(x = iter,y = elbo,color = init)) +
             geom_line(size = 0.75) +
			 scale_y_continuous(trans = "log10") +
		 scale_color_manual(values=c("darkblue","dodgerblue","darkorange")) +
			 labs(x = "iteration",y = "ELBO difference") +
			 theme_cowplot(font_size = 10)
print(p5)
```

Next we will see an example in which EM updates fail to make
reasonable progress.

```{r plots-for-paper-1, echo=FALSE, results="hide"}
ggsave("../plots/structure_plot_sim1.pdf",p1,width = 4,height = 1.25)
ggsave("../plots/progress_plot_sim1.pdf",plot_grid(p2,p3),width=5,height=1.7)
ggsave("../plots/loadings_scatterplot_sim1.pdf",p4,width = 2.5,height = 2)
ggsave("../plots/progress_plot_lda_sim1.pdf",p5,width = 2.5,height = 1.7)
```

Correlated topics scenario
--------------------------

The count data in this second example are simulated as before, with
one difference: by setting $s_{56} = s_{65} = 8$, the mixture
proportions for topics 5 and 6 are no longer close to orthogonal.

```{r simulate-data-2}
set.seed(1)
S[5,6] <- 8
S[6,5] <- 8
L <- simulate_loadings(n,k,S)
X <- simulate_multinom_counts(L,F,s)
X <- X[,colSums(X > 0) > 0]
```

Compare this Structure plot to the one above---there is more mixing of
topics 5 and 6:

```{r structure-plot-2, fig.width=6, fig.height=1.5, message=FALSE}
y <- apply(L,1,which.max)
y <- rank(y,ties.method = "random")
y <- qqnorm(y,plot.it = FALSE)$x
fit <- list(L = L)
class(fit) <- c("multinom_topic_model_fit","list")
structure_plot(fit,topics = 1:6,colors = topic_colors,perplexity = 30,
               Y_init = matrix(y),verbose = FALSE)
```

As before, we run the EM and SCD updates to fit the multinomial topic
model, with a twist that we perform another round of SCD updates after
running the EM updates. This will be explained shortly.

```{r fit-5, results="hide", message=FALSE}
fit0 <- fit_poisson_nmf(X,k,numiter = 50,method = "em",
                        control = list(extrapolate = FALSE,numiter = 4))
fit1 <- fit_poisson_nmf(X,fit0 = fit0,numiter = 750,method = "em",
                        control = list(extrapolate = FALSE,numiter = 4))
fit2 <- fit_poisson_nmf(X,fit0 = fit0,numiter = 950,method = "scd",
                        control = list(extrapolate = FALSE,numiter = 4))
fit3 <- fit_poisson_nmf(X,fit0 = fit1,numiter = 200,method = "scd",
                        control = list(extrapolate = FALSE,numiter = 4))
fit1 <- fit_poisson_nmf(X,fit0 = fit1,numiter = 200,method = "em",
                        control = list(extrapolate = FALSE,numiter = 4))
fit1 <- poisson2multinom(fit1)
fit2 <- poisson2multinom(fit2)
fit3 <- poisson2multinom(fit3)
```

In this second example, after initially making good progress, the EM
estimates remain very far from the solution achieved by SCD even after
hundreds of EM updates. This isn't a case where the EM updates have
settled on a different local solution---the SCD updates quickly
"rescue" the EM estimates.

```{r plot-progress-2, fig.width=6, fig.height=2}
pdat <- rbind(data.frame(iter   = 1:1000,
                         loglik = fit1$progress$loglik.multinom,
                         res    = fit1$progress$res,
                         method = "em"),
              data.frame(iter   = 1:1000,
                         loglik = fit2$progress$loglik.multinom,
                         res    = fit2$progress$res,
                         method = "scd"),
              data.frame(iter   = 800:1000,
                         loglik = fit3$progress[800:1000,"loglik.multinom"],
                         res    = fit3$progress[800:1000,"res"],
  			             method = "em+scd"))
pdat <- transform(pdat,loglik = max(loglik) - loglik)
pdat <- subset(pdat,iter >= 50)
p3 <- ggplot(pdat,aes(x = iter,y = loglik,color = method)) +
  geom_line(size = 0.75) +
  scale_color_manual(values = c("dodgerblue","darkorange","magenta")) +
  labs(x = "iteration",y = "log-likelihood difference") +
  theme_cowplot(font_size = 10)
p4 <- ggplot(pdat,aes(x = iter,y = res,color = method)) +
  geom_line(size = 0.75) +
  scale_color_manual(values = c("dodgerblue","darkorange","magenta")) +
  ylim(0,10) +
  labs(x = "iteration",y = "max KKT residual") +
  theme_cowplot(font_size = 10)
plot_grid(p3,p4)
```

This large difference in likelihood is not due to a trivial difference
in solution---for example, there are many large differences in the
topic proportion estimates:

```{r loadings-scatterplot-2, fig.width=3, fig.height=2.5}
pdat <- data.frame(x = as.vector(fit1$L),
                   y = as.vector(fit2$L),
                   k = factor(rep(1:6,each = 100)))
ggplot(pdat,aes(x = x,y = y,fill = k)) +
  geom_point(color = "white",shape = 21,size = 1.75) +
  geom_abline(intercept = 0,slope = 1,color = "skyblue",linetype = "dotted") +
  scale_fill_manual(values = topic_colors) +
  labs(x = "em",y = "scd") +
  theme_cowplot(font_size = 10)
```

Most of the samples contributing to the large difference in likehood
are samples generated from combinations of topics 5 and 6 (the X and Y
axes in this scatterplot show the per-sample log-likelihoods):

```{r likelihood-scatterplot, fig.width=3.5, fig.height=2.5}
pdat <- data.frame(x = loglik_multinom_topic_model(X,fit1),
                   y = loglik_multinom_topic_model(X,fit2))
ggplot(pdat,aes(x = x,y = y,fill = L[,5] + L[,6])) +
  geom_point(color = "white",shape = 21,size = 1.75) +
  geom_abline(intercept = 0,slope = 1,color = "black",linetype = "dotted") +
  scale_fill_gradient(low = "skyblue",high = "orangered") +
  xlim(-700,-100) +
  ylim(-700,-100) +
  labs(x = "em",y = "scd",fill = "topic 5 + 6") +
  theme_cowplot(font_size = 10)
```

These results suggest that the EM algorithm may perform poorly in
settings where the topics are correlated, even if the correlations are
quite modest.
